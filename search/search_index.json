{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"Data Testing Tutorial You're a data scientist, and you're having fun with your data. You might write a lot of code in support of your project, and enjoying it a ton too! But at some point, things get out of control. The functions you've copied from one notebook to another proliferate across the project, and suddenly, you're not so sure which function is \"the one\" you trust. Also, the data seem to be changing underneath you, with unexpected errors cropping up in the form of null values, invalid values, and more. Sounds familiar? If you're on the lookout for a short guidebook to solving these problems, this one will give you the fundamentals. Come join me as I show you how the incorporation of two, namely software testing and schema validation, can help bring a measure of sanity to your data science workflow as a data scientist. What to expect Throughout these notebooks, we will be covering two key themes: Software testing, via pytest and hypothesis , and Data validation, using a mixture of custom Python functions and pandera . Software testing involves running commands at the terminal, as such the notebooks on software testing are designed to be read. By contrast, data validation involves running code in the notebook. As such, those notebooks on data validation are intended to be executed. Let's get going! Head over to the first chapter to learn how to get setup!","title":"Home"},{"location":"#data-testing-tutorial","text":"You're a data scientist, and you're having fun with your data. You might write a lot of code in support of your project, and enjoying it a ton too! But at some point, things get out of control. The functions you've copied from one notebook to another proliferate across the project, and suddenly, you're not so sure which function is \"the one\" you trust. Also, the data seem to be changing underneath you, with unexpected errors cropping up in the form of null values, invalid values, and more. Sounds familiar? If you're on the lookout for a short guidebook to solving these problems, this one will give you the fundamentals. Come join me as I show you how the incorporation of two, namely software testing and schema validation, can help bring a measure of sanity to your data science workflow as a data scientist.","title":"Data Testing Tutorial"},{"location":"#what-to-expect","text":"Throughout these notebooks, we will be covering two key themes: Software testing, via pytest and hypothesis , and Data validation, using a mixture of custom Python functions and pandera . Software testing involves running commands at the terminal, as such the notebooks on software testing are designed to be read. By contrast, data validation involves running code in the notebook. As such, those notebooks on data validation are intended to be executed.","title":"What to expect"},{"location":"#lets-get-going","text":"Head over to the first chapter to learn how to get setup!","title":"Let's get going!"},{"location":"1-getting-setup/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction Here are the ways that you can get setup to work with this tutorial repository. Use Binder The first option is to user Binder! Simply click on the link below. Use VSCode's Dev Containers Another way you can interact with the notebooks is to use VSCode's development containers. Fire up VSCode, and in the command palette, search for Remote Containers: Open Repository in Container , and then paste the URL to this repository in there. Get Setup Manually To get setup manually: Clone the repository locally. cd to the repository. Install the environment: conda env create -f environment.yml Install the Jupyter kernel: python -m ipykernel install --user --name datatest Run Jupyterlab: jupyter lab Are you ready? Head over to the next section to continue learning more!","title":"Getting Started"},{"location":"1-getting-setup/#introduction","text":"Here are the ways that you can get setup to work with this tutorial repository.","title":"Introduction"},{"location":"1-getting-setup/#use-binder","text":"The first option is to user Binder! Simply click on the link below.","title":"Use Binder"},{"location":"1-getting-setup/#use-vscodes-dev-containers","text":"Another way you can interact with the notebooks is to use VSCode's development containers. Fire up VSCode, and in the command palette, search for Remote Containers: Open Repository in Container , and then paste the URL to this repository in there.","title":"Use VSCode's Dev Containers"},{"location":"1-getting-setup/#get-setup-manually","text":"To get setup manually: Clone the repository locally. cd to the repository. Install the environment: conda env create -f environment.yml Install the Jupyter kernel: python -m ipykernel install --user --name datatest Run Jupyterlab: jupyter lab Are you ready? Head over to the next section to continue learning more!","title":"Get Setup Manually"},{"location":"2-prerequisite-knowledge/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction In this notebook, I will go over with you some fundamental concepts that are super important for data scientists to know. I will also go through with you why they are important, and how ignoring them will impact your workflow in negative ways. Virtual Environments Virtual environments are the first foundational concept you should know. This is the process of creating a software stack for a given project with as few things shared with other projects as possible. Docker containers At one extreme of virtual environments is Docker containers. Here, the entire software stack encompasses a whole Linux operating system, basically short of \"which CPU it runs on\". Here, any system libraries, Python packages, C libraries are packaged into a single logical \"unit\", which can be distributed to others easily as well. Docker containers are canonically declared in a Dockerfile (though you can name it whatever you want), which contains bash-like instructions (mixed with Docker-specific syntax) to build the environment. conda environments For data scientists, a more constrained type of environment are conda environments. Here, we leave system-level libraries alone, and instead are focused on packages that we need for our data science work. The line between system-level and project-level is kind of blurry, though a good conceptual way of thinking about this is to assign \"packages I import\" to the category of data science packages , and everything else to system packages . conda environments are canonically declared in an environment.yml file (though you can name it whatever you want), and use YAML syntax to declare the environment nam,e what packages you want in the environment, and where to pull them from. venv environments For Python developers specifically, one level more constrained is to use virtualenv . Here, only the Python interpreter and Python packages are packaged into an isolated software stack that no other projects should touch. venv is quite lightweight, though it is restricted to Python packages only. venv environments depend only on having venv installed on your system, and use requirements.txt to build the Python environment. What happens if you don't use a custom environment? Initially, you might not notice much. But over time, if all of your projects share the same environment, you might end up with conflicting package requirements that cannot be resolved. I once thought that environments were super troublesome, and installed everything into the macOS system environment. That caused me a ton of troubles a few months later, when I was trying to update my compute stack. I ended up with conflicting packages, and couldn't execute my code reliably, following which I decided to nuked the environment... and promptly cause iPhoto to always crash on launch. (Turns out iPhoto depends on macOS' system Python.) It was then that I knew: I had to use environments. I chose conda for it was (and still is) the lightest-weight way to create very well-isolated environments on a single compute system. Once I got the hang of it, every project got its own conda environment , no exceptions. Even this tutorial follows that practice. Take it from someone who's learned his lesson the hard way: Use conda environments! Creating conda environments For those of you who did a manual setup, you've already got experience with this! For others, the generic instructions are as follows. Firstly, cd to the project directory, and ensure that there is an environment.yml file in there. If you want the conda environment to be recognized by an identifiable name in Jupyter, then make sure that the environment spec contains ipykernel under the dependencies section. Next, create the conda environment specified in the environment.yml file by running the following command at the terminal: conda env create -f environment.yml To ensure that the conda environment is recognized by Jupyter, set it up with ipykernel : export ENVIRONMENT_NAME = \"..........\" # put your environment's name here. python -m ipykernel install --user --name $ENVIRONMENT_NAME Custom Packages If you didn't know already, it's totally possible for you to build custom packages of your own! I'm going to show you the simplest way of handling a custom source package here. Assumed project structure Firstly, let's assume that you have the following project structure: ./ |- docs/ |- notebooks/ |- README.md Create custom source package The first thing you'll want to do is make a src directory in your project root. ( src is lazy programmer's way of indicating \"source\".) mkdir src Next, you'll want to navigate to your src/ directory and create a setup.py file. cd src touch setup.py Now, edit setup.py using your favourite text editor. You'll want the bare minimum to look like this: \"\"\"Setup script.\"\"\" import os from setuptools import setup , find_packages setup ( # Give it any name you want, but I recommend it being short and easy to type. name = \"project_name\" , # Put a dummy version in place version = \"0.1\" , # Make sure all packages can be found. packages = find_packages (), ) You don't need much else beyond that. Save the text file. Populate your source code package Now, you can start creating your library of functions in a package. Let's call the package project_name , which will make it consistent with the name=\"project_name\" kwarg that you put in setup.py : mkdir project_name cd project_name touch __init__.py The __init__.py is the \"magic\" file that enables find_packages() to discover that project_name/ is a Python package to be installed! Go ahead and edit __init__.py , and add in any kind of function you want. If this is your first time making a Python package, then follow me and add the following function inside __init__.py : def hello (): print ( \"Hello!\" ) Now, your src/ directory should look something like this: ./ |- src/ |- setup.py |- project_name/ |- __init__.py You might be wondering now: So yeah, I've defined the function there, but how am I ever going to use this function? Install custom source package into environment Well, now we're going to install the custom package inside your environment! I'm assuming that you've already activated your environment here, and that you have pip installed inside there (every conda environment should have it). Firstly, navigate to the src/ directory. (The one that contains setup.py .) Next, tell pip to install your custom package in \"editable\" mode. pip install -e . \"Editable\" mode will give you the ability to change the source on-the-fly, and have those changes reflected on every new invocation of Python! Verify that the package is installed That's it! If you want to verify that the package has been installed correctly, navigate to the project root directory, i.e. the one with notebooks/ and README.md in it. Then, run Python from there: python Now, try importing the hello function. >>> from project_name import hello >>> hello () \"Hello!\" If you get the printed \"Hello!\" , then everything is installed correctly Populate more source files! You can add more source .py files in the package, to logically organize things. For example, if you have data loaders, you can add them to a project_name/data.py file, and they will then be accessible from the project_name.data namespace. What happens if you don't use a custom project source? Well, you end up with notebooks that are populated with lots of functions, which might need to be copied and pasted from notebook to notebook... which will lead to confusion later as you try to untangle, \"which exactly was the source-of-truth version of the function??\" Or you might resort to cloning entire notebooks, and suffixing them with _v1 , _v2 , or _some_other_purpose ... still not ideal at all. By instead using a custom source package, you get a single source of truth for custom functions that you might have written, which you can use from notebook to notebook. (Doing so also helps with testing your code, which I hear is the purpose of this tutorial!) You might be tempted to use your Jupyter notebooks as a source file, say, using some of fast.ai 's tooling. I'd encourage you to avoid doing that too, as the simple act of hand-curating the functions that you need nudges you to think very clearly about how your project should be structured. The discipline now pays off compound interest dividends in time saved later on, especially if your project is a fairly medium-term to long-term-ish kind of project (on the order of months to years), or if you have a good hunch that the project may make it to \"production\" (whatever that looks like for you). Your engineering colleagues will thank you for giving a starting point that already includes a custom source library.","title":"Prerequisite Knowledge"},{"location":"2-prerequisite-knowledge/#introduction","text":"In this notebook, I will go over with you some fundamental concepts that are super important for data scientists to know. I will also go through with you why they are important, and how ignoring them will impact your workflow in negative ways.","title":"Introduction"},{"location":"2-prerequisite-knowledge/#virtual-environments","text":"Virtual environments are the first foundational concept you should know. This is the process of creating a software stack for a given project with as few things shared with other projects as possible.","title":"Virtual Environments"},{"location":"2-prerequisite-knowledge/#docker-containers","text":"At one extreme of virtual environments is Docker containers. Here, the entire software stack encompasses a whole Linux operating system, basically short of \"which CPU it runs on\". Here, any system libraries, Python packages, C libraries are packaged into a single logical \"unit\", which can be distributed to others easily as well. Docker containers are canonically declared in a Dockerfile (though you can name it whatever you want), which contains bash-like instructions (mixed with Docker-specific syntax) to build the environment.","title":"Docker containers"},{"location":"2-prerequisite-knowledge/#conda-environments","text":"For data scientists, a more constrained type of environment are conda environments. Here, we leave system-level libraries alone, and instead are focused on packages that we need for our data science work. The line between system-level and project-level is kind of blurry, though a good conceptual way of thinking about this is to assign \"packages I import\" to the category of data science packages , and everything else to system packages . conda environments are canonically declared in an environment.yml file (though you can name it whatever you want), and use YAML syntax to declare the environment nam,e what packages you want in the environment, and where to pull them from.","title":"conda environments"},{"location":"2-prerequisite-knowledge/#venv-environments","text":"For Python developers specifically, one level more constrained is to use virtualenv . Here, only the Python interpreter and Python packages are packaged into an isolated software stack that no other projects should touch. venv is quite lightweight, though it is restricted to Python packages only. venv environments depend only on having venv installed on your system, and use requirements.txt to build the Python environment.","title":"venv environments"},{"location":"2-prerequisite-knowledge/#what-happens-if-you-dont-use-a-custom-environment","text":"Initially, you might not notice much. But over time, if all of your projects share the same environment, you might end up with conflicting package requirements that cannot be resolved. I once thought that environments were super troublesome, and installed everything into the macOS system environment. That caused me a ton of troubles a few months later, when I was trying to update my compute stack. I ended up with conflicting packages, and couldn't execute my code reliably, following which I decided to nuked the environment... and promptly cause iPhoto to always crash on launch. (Turns out iPhoto depends on macOS' system Python.) It was then that I knew: I had to use environments. I chose conda for it was (and still is) the lightest-weight way to create very well-isolated environments on a single compute system. Once I got the hang of it, every project got its own conda environment , no exceptions. Even this tutorial follows that practice. Take it from someone who's learned his lesson the hard way: Use conda environments!","title":"What happens if you don't use a custom environment?"},{"location":"2-prerequisite-knowledge/#creating-conda-environments","text":"For those of you who did a manual setup, you've already got experience with this! For others, the generic instructions are as follows. Firstly, cd to the project directory, and ensure that there is an environment.yml file in there. If you want the conda environment to be recognized by an identifiable name in Jupyter, then make sure that the environment spec contains ipykernel under the dependencies section. Next, create the conda environment specified in the environment.yml file by running the following command at the terminal: conda env create -f environment.yml To ensure that the conda environment is recognized by Jupyter, set it up with ipykernel : export ENVIRONMENT_NAME = \"..........\" # put your environment's name here. python -m ipykernel install --user --name $ENVIRONMENT_NAME","title":"Creating conda environments"},{"location":"2-prerequisite-knowledge/#custom-packages","text":"If you didn't know already, it's totally possible for you to build custom packages of your own! I'm going to show you the simplest way of handling a custom source package here.","title":"Custom Packages"},{"location":"2-prerequisite-knowledge/#assumed-project-structure","text":"Firstly, let's assume that you have the following project structure: ./ |- docs/ |- notebooks/ |- README.md","title":"Assumed project structure"},{"location":"2-prerequisite-knowledge/#create-custom-source-package","text":"The first thing you'll want to do is make a src directory in your project root. ( src is lazy programmer's way of indicating \"source\".) mkdir src Next, you'll want to navigate to your src/ directory and create a setup.py file. cd src touch setup.py Now, edit setup.py using your favourite text editor. You'll want the bare minimum to look like this: \"\"\"Setup script.\"\"\" import os from setuptools import setup , find_packages setup ( # Give it any name you want, but I recommend it being short and easy to type. name = \"project_name\" , # Put a dummy version in place version = \"0.1\" , # Make sure all packages can be found. packages = find_packages (), ) You don't need much else beyond that. Save the text file.","title":"Create custom source package"},{"location":"2-prerequisite-knowledge/#populate-your-source-code-package","text":"Now, you can start creating your library of functions in a package. Let's call the package project_name , which will make it consistent with the name=\"project_name\" kwarg that you put in setup.py : mkdir project_name cd project_name touch __init__.py The __init__.py is the \"magic\" file that enables find_packages() to discover that project_name/ is a Python package to be installed! Go ahead and edit __init__.py , and add in any kind of function you want. If this is your first time making a Python package, then follow me and add the following function inside __init__.py : def hello (): print ( \"Hello!\" ) Now, your src/ directory should look something like this: ./ |- src/ |- setup.py |- project_name/ |- __init__.py You might be wondering now: So yeah, I've defined the function there, but how am I ever going to use this function?","title":"Populate your source code package"},{"location":"2-prerequisite-knowledge/#install-custom-source-package-into-environment","text":"Well, now we're going to install the custom package inside your environment! I'm assuming that you've already activated your environment here, and that you have pip installed inside there (every conda environment should have it). Firstly, navigate to the src/ directory. (The one that contains setup.py .) Next, tell pip to install your custom package in \"editable\" mode. pip install -e . \"Editable\" mode will give you the ability to change the source on-the-fly, and have those changes reflected on every new invocation of Python!","title":"Install custom source package into environment"},{"location":"2-prerequisite-knowledge/#verify-that-the-package-is-installed","text":"That's it! If you want to verify that the package has been installed correctly, navigate to the project root directory, i.e. the one with notebooks/ and README.md in it. Then, run Python from there: python Now, try importing the hello function. >>> from project_name import hello >>> hello () \"Hello!\" If you get the printed \"Hello!\" , then everything is installed correctly","title":"Verify that the package is installed"},{"location":"2-prerequisite-knowledge/#populate-more-source-files","text":"You can add more source .py files in the package, to logically organize things. For example, if you have data loaders, you can add them to a project_name/data.py file, and they will then be accessible from the project_name.data namespace.","title":"Populate more source files!"},{"location":"2-prerequisite-knowledge/#what-happens-if-you-dont-use-a-custom-project-source","text":"Well, you end up with notebooks that are populated with lots of functions, which might need to be copied and pasted from notebook to notebook... which will lead to confusion later as you try to untangle, \"which exactly was the source-of-truth version of the function??\" Or you might resort to cloning entire notebooks, and suffixing them with _v1 , _v2 , or _some_other_purpose ... still not ideal at all. By instead using a custom source package, you get a single source of truth for custom functions that you might have written, which you can use from notebook to notebook. (Doing so also helps with testing your code, which I hear is the purpose of this tutorial!) You might be tempted to use your Jupyter notebooks as a source file, say, using some of fast.ai 's tooling. I'd encourage you to avoid doing that too, as the simple act of hand-curating the functions that you need nudges you to think very clearly about how your project should be structured. The discipline now pays off compound interest dividends in time saved later on, especially if your project is a fairly medium-term to long-term-ish kind of project (on the order of months to years), or if you have a good hunch that the project may make it to \"production\" (whatever that looks like for you). Your engineering colleagues will thank you for giving a starting point that already includes a custom source library.","title":"What happens if you don't use a custom project source?"},{"location":"3-pytest-introduction/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Introduction to pytest In this chapter, we are going to introduce you to pytest , a library for unit testing your code in Python. The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. Unit testing fundamentals If this is your first time learning about unit testing, read on this section for a crash course on what it's all about. (If you're familiar with unit testing, but want to know more about pytest 's idioms, move on to the next section.) From Wikipedia : unit testing is a software testing method by which individual units of source code\u2014sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures\u2014are tested to determine whether they are fit for use. If that sounded confusing, fret not: here's a colloquial version that might help you: Unit testing is a software testing method where we test logical \"units\" of source code, in isolation from other \"units\" of source code, to make sure they work as expected. For the astute amongst you, there's a key skill involved in unit testing: that is learning how to break a problem down into logical \"units\" of work. This is an art, is problem-dependent, and developing a shared taste with others takes practice and time; learning how to write unit tests will accelerate your development on this matter. pytest idioms Before I get you writing code, it's important to make sure that you know some of pytest 's idioms. Firstly, pytest expects that the block of code that you want to test is wrapped inside a function or a class. That way, you can import it into your testing suite (more on what the \"testing suite\" is later!). In other words, you should have a function defined in an importable module, and that module should be installed in the conda environment. (And if even this paragraph feels awkward to you, I'd recommend reading the \"Prerequisite Knowledge\" chapter again.) Secondly, pytest looks for all files that are prefixed with test_ (for example, test_something.py ), and then looks for all functions in those files that are also prefixed with test_ (for example def test_somefunc() ). Those will then comprise the \"test suite\" for your project. Thirdly, pytest is invoked at the command line. A single basic command, with no configuration flags, looks like this: pytest . This tells pytest to look recursively under the current working directory for all tests to execute, and then it will execute them in order. Exercises in Testing With that background information out of the way, I'm going to give you a few exercises to get your hands wet with testing. Exercise 1: Write a test for the increment function. We have provided a function inside this tutorial's custom source, under testing_tutorial.functions , called increment . The source code for the function is below: from testing_tutorial.functions import increment increment ?? We're going to use this function to show you the anatomy of writing a test. Firstly, we define a new function that informatively identifies it as a test for increment: def test_increment (): pass Now, we can fill it up with the \"setup\" for the test, i.e. the inputs that go into the function. def test_increment (): x = 1 # one example, \"set up\" to be passed into the test. Then, we execute the function to be tested using the setup inputs: def test_increment (): x = 1 # setup to be passed into the test. result = increment ( x ) # execute the function Finally, we assert that the result matches some expectation: def test_increment (): x = 1 # setup to be passed into the test. result = increment ( x ) # execute the function and get result. assert result == 2 # assert equality of result with expectation. </ div > </ div > </ div > < div class = \"cell border-box-sizing text_cell rendered\" markdown = \"1\" > < div class = \"inner_cell\" markdown = \"1\" > < div class = \"text_cell_render border-box-sizing rendered_html\" markdown = \"1\" > Now , I 'd like you to write a more general version of this test, and place it inside `./src/testing_tutorial/tests/test_functions_student.py`. Don' t break your skull trying to come up with a mathematically rigorous version , though . The intent here is to make sure you 're actually thinking about some form of testing, and not just copy/pasting code. </ div > </ div > </ div > < div class = \"cell border-box-sizing text_cell rendered\" markdown = \"1\" > < div class = \"inner_cell\" markdown = \"1\" > < div class = \"text_cell_render border-box-sizing rendered_html\" markdown = \"1\" > Now , in your terminal , execute the following command : ``` bash $ pytest This is the output you should expect: $ pytest ================================= test session starts ================================= platform darwin -- Python 3 .6.10, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 rootdir: /Users/ericmjl/github/tutorials/data-testing-tutorial/src plugins: cov-2.10.1 collected 2 items tests/test_functions.py .. [ 100 % ] ================================== 2 passed in 0 .04s ================================== This tells you that: The collected 2 items indicates how many test functions were written. The bottom line contains tests/test_functions.py , and is the place where the tests showed up. (These are the instructor versions, yours should show up under tests/test_functions_student.py ) The .. shows that the tests passed! (If they failed, they would show up with red X s.) Congratulations! You have written the first test of the tutorial! Exercise 2: Simulating what happens when you accidentally break code We're now going to simulate what happens when you accidentally break your code. Go ahead and change the increment function in functions.py such that it returns the wrong thing. Then, execute the test suite! You should see something that looks like the following: ================================= test session starts ================================= platform darwin -- Python 3.6.10, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 rootdir: /Users/ericmjl/github/tutorials/data-testing-tutorial/src plugins: cov-2.10.1 collected 2 items tests/test_functions.py FF [100%] ====================================== FAILURES ======================================= ___________________________________ test_increment ____________________________________ def test_increment(): \"\"\"Test for increment function.\"\"\" x = 1 result = increment(x) > assert result == 2 E assert 3 == 2 tests/test_functions.py:8: AssertionError _______________________________ test_increment_general ________________________________ def test_increment_general(): \"\"\"A slightly more test for increment function.\"\"\" x = 1 result = increment(x) > assert result - 1 == x E assert (3 - 1) == 1 tests/test_functions.py:15: AssertionError =============================== short test summary info =============================== FAILED tests/test_functions.py::test_increment - assert 3 == 2 FAILED tests/test_functions.py::test_increment_general - assert (3 - 1) == 1 ================================== 2 failed in 0.27s ================================== Now, we'll see the tests fail, and the error messages will show us what's wrong! Reading the test error message immediately tells us that the function that failed the test was increment . In particular, it failed both the example-based test and the slightly more general test. When we execute the test, we've caught where breaking changes happen, because the tests serve as an independent check on the correctness of the function. Go ahead and fix the test, then re-run the test suite. Everything should now pass. Some notes This is a very good just-in-time moment to emphasize a few points points. Anatomy of a Test Firstly, let's revise now what the anatomy of a test is like. You will always have a setup, a result from the execution of the function, and an assertion about the result. from module import function def test_function (): # `test_` in the name is very important! \"\"\"Docstring about the test.\"\"\" setup_value = ... # set up the test result = function ( setup_value ) # execution of the function assert result == correct_val # assertion statement The function should do something that is \"testable\", and ideally, it should run fast (like under a few hundred milliseconds). After all, if you start accumulating a bunch of functions and need to test them, then you'll end up waiting a long time for all of your tests to run. Testing Loop The other thing to introduce just-in-time here is the so-called \"testing loop\": Write a test for a function. Write the function. Execute pytest . Go back to step 1. There's nothing complex behind the ideas of testing, 80% of your cases will boil down to doing this loop. What kinds of tests There are a few kinds of tests that you can write, and I'll list here the \"bare minimum\". Execution tests If you don't do anything else, then simply executing the test and making sure it runs without erroring is better than nothing. (Basically, just eliminate the assertions.) I don't recommend doing this for everything, but if you're genuinely at a loss, then call the function inside the test and just make sure it doesn't error out. Example-based tests I did this in test_increment , where I provided one example input in the test, and tested that the expected result was some exact value. This is already one level up from a simple execution test. Parametrized tests You can read more about parametrizing a test on the pytest docs . Here, we parametrize the test function, so that pytest can provide to it a range of examples that we have pre-defined. Property-based tests If you read test_increment_general , that is an example of a property-based test. There, we test a property of the output that is invariant to the input given, i.e. that the output should always be one more than the input, regardless of what input is given. In the later chapters, you will see how to do this with Hypothesis. Exercise 3: Testing a Min-Max Scaler In functions.py , we have a function called min_max_scaler(x) for your data. It takes in a numpy array and scales all of the values to be between 0 and 1 inclusive. The min value should be 0, and the max value should be 1. Try writing a test for the min-max scaler. It should check the following: Given a particular array-like input (e.g. numpy array, list, tuples), it should be equal to some other array. Use the np.allclose(arr1, arr2) function to test closeness of two floating point values. The minimum value should be 0, and the maximum value of the output should be 1. Note: This function is also implemented in the scikit-learn library as part of their preprocessing module. However, in case an engineering decision that you make is that you don't want to import an entire library just to use one function, it is considered good practice to rewrite it on your own, provided you also test it sufficiently. Once you're done, execute the test and check that the min_max_scaler adheres to the behaviour laid out in its docstring. Exercise 4: Testing functions on textual data. Imagine we have textual data, and we want to clean it up. There are two functions we may want to write to standardize the data: bag_of_words(text) , which takes in the text and tokenizes the text into its set of constituent words. strip_punctuation(text) , which strips punctuation from the text. Now, I'd like you to invert the flow we've been following, and start by designing the tests first, before implementing the two functions in src/student_functions.py ; you may wish to write additional helper functions to manage the business logic. There's leeway in this exercise; feel free to get creative! (And if you want a reference starting point, feel free to peek inside src/functions.py !) The reason I'm asking you to design the tests first is because that will clarify how you intend to use the function, which will bring much more clarity to how you implement the function. This is also known as \"Test-Driven Development\". Once you're done, execute the tests and make sure they all pass. Conclusions This level of testing is sufficient to get you through 80% of the day-to-day. I have used this level of testing at work to raise the level of confidence I have in the functions I write. It facilitates code sharing as well, because my colleagues can now have the confidence that the code I write is reliable and works as expected. My engineering colleagues will have confidence in taking over what I have developed, because they know they have an easy starting point for studying the code (in the test suite). There are advanced patterns for testing that I have not gone through here, such as parametrizing the tests, checking that errors are raised, and more. For these, the pytest docs are a wonderful resource, and I would encourage you to check them out. Meanwhile, we are going to go to the next chapter, which is on how writing tests for our data.","title":"Introduction to pytest"},{"location":"3-pytest-introduction/#introduction-to-pytest","text":"In this chapter, we are going to introduce you to pytest , a library for unit testing your code in Python. The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.","title":"Introduction to pytest"},{"location":"3-pytest-introduction/#unit-testing-fundamentals","text":"If this is your first time learning about unit testing, read on this section for a crash course on what it's all about. (If you're familiar with unit testing, but want to know more about pytest 's idioms, move on to the next section.) From Wikipedia : unit testing is a software testing method by which individual units of source code\u2014sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures\u2014are tested to determine whether they are fit for use. If that sounded confusing, fret not: here's a colloquial version that might help you: Unit testing is a software testing method where we test logical \"units\" of source code, in isolation from other \"units\" of source code, to make sure they work as expected. For the astute amongst you, there's a key skill involved in unit testing: that is learning how to break a problem down into logical \"units\" of work. This is an art, is problem-dependent, and developing a shared taste with others takes practice and time; learning how to write unit tests will accelerate your development on this matter.","title":"Unit testing fundamentals"},{"location":"3-pytest-introduction/#pytest-idioms","text":"Before I get you writing code, it's important to make sure that you know some of pytest 's idioms. Firstly, pytest expects that the block of code that you want to test is wrapped inside a function or a class. That way, you can import it into your testing suite (more on what the \"testing suite\" is later!). In other words, you should have a function defined in an importable module, and that module should be installed in the conda environment. (And if even this paragraph feels awkward to you, I'd recommend reading the \"Prerequisite Knowledge\" chapter again.) Secondly, pytest looks for all files that are prefixed with test_ (for example, test_something.py ), and then looks for all functions in those files that are also prefixed with test_ (for example def test_somefunc() ). Those will then comprise the \"test suite\" for your project. Thirdly, pytest is invoked at the command line. A single basic command, with no configuration flags, looks like this: pytest . This tells pytest to look recursively under the current working directory for all tests to execute, and then it will execute them in order.","title":"pytest idioms"},{"location":"3-pytest-introduction/#exercises-in-testing","text":"With that background information out of the way, I'm going to give you a few exercises to get your hands wet with testing.","title":"Exercises in Testing"},{"location":"3-pytest-introduction/#exercise-1-write-a-test-for-the-increment-function","text":"We have provided a function inside this tutorial's custom source, under testing_tutorial.functions , called increment . The source code for the function is below: from testing_tutorial.functions import increment increment ?? We're going to use this function to show you the anatomy of writing a test. Firstly, we define a new function that informatively identifies it as a test for increment: def test_increment (): pass Now, we can fill it up with the \"setup\" for the test, i.e. the inputs that go into the function. def test_increment (): x = 1 # one example, \"set up\" to be passed into the test. Then, we execute the function to be tested using the setup inputs: def test_increment (): x = 1 # setup to be passed into the test. result = increment ( x ) # execute the function Finally, we assert that the result matches some expectation: def test_increment (): x = 1 # setup to be passed into the test. result = increment ( x ) # execute the function and get result. assert result == 2 # assert equality of result with expectation. </ div > </ div > </ div > < div class = \"cell border-box-sizing text_cell rendered\" markdown = \"1\" > < div class = \"inner_cell\" markdown = \"1\" > < div class = \"text_cell_render border-box-sizing rendered_html\" markdown = \"1\" > Now , I 'd like you to write a more general version of this test, and place it inside `./src/testing_tutorial/tests/test_functions_student.py`. Don' t break your skull trying to come up with a mathematically rigorous version , though . The intent here is to make sure you 're actually thinking about some form of testing, and not just copy/pasting code. </ div > </ div > </ div > < div class = \"cell border-box-sizing text_cell rendered\" markdown = \"1\" > < div class = \"inner_cell\" markdown = \"1\" > < div class = \"text_cell_render border-box-sizing rendered_html\" markdown = \"1\" > Now , in your terminal , execute the following command : ``` bash $ pytest This is the output you should expect: $ pytest ================================= test session starts ================================= platform darwin -- Python 3 .6.10, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 rootdir: /Users/ericmjl/github/tutorials/data-testing-tutorial/src plugins: cov-2.10.1 collected 2 items tests/test_functions.py .. [ 100 % ] ================================== 2 passed in 0 .04s ================================== This tells you that: The collected 2 items indicates how many test functions were written. The bottom line contains tests/test_functions.py , and is the place where the tests showed up. (These are the instructor versions, yours should show up under tests/test_functions_student.py ) The .. shows that the tests passed! (If they failed, they would show up with red X s.) Congratulations! You have written the first test of the tutorial!","title":"Exercise 1: Write a test for the increment function."},{"location":"3-pytest-introduction/#exercise-2-simulating-what-happens-when-you-accidentally-break-code","text":"We're now going to simulate what happens when you accidentally break your code. Go ahead and change the increment function in functions.py such that it returns the wrong thing. Then, execute the test suite! You should see something that looks like the following: ================================= test session starts ================================= platform darwin -- Python 3.6.10, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 rootdir: /Users/ericmjl/github/tutorials/data-testing-tutorial/src plugins: cov-2.10.1 collected 2 items tests/test_functions.py FF [100%] ====================================== FAILURES ======================================= ___________________________________ test_increment ____________________________________ def test_increment(): \"\"\"Test for increment function.\"\"\" x = 1 result = increment(x) > assert result == 2 E assert 3 == 2 tests/test_functions.py:8: AssertionError _______________________________ test_increment_general ________________________________ def test_increment_general(): \"\"\"A slightly more test for increment function.\"\"\" x = 1 result = increment(x) > assert result - 1 == x E assert (3 - 1) == 1 tests/test_functions.py:15: AssertionError =============================== short test summary info =============================== FAILED tests/test_functions.py::test_increment - assert 3 == 2 FAILED tests/test_functions.py::test_increment_general - assert (3 - 1) == 1 ================================== 2 failed in 0.27s ================================== Now, we'll see the tests fail, and the error messages will show us what's wrong! Reading the test error message immediately tells us that the function that failed the test was increment . In particular, it failed both the example-based test and the slightly more general test. When we execute the test, we've caught where breaking changes happen, because the tests serve as an independent check on the correctness of the function. Go ahead and fix the test, then re-run the test suite. Everything should now pass.","title":"Exercise 2: Simulating what happens when you accidentally break code"},{"location":"3-pytest-introduction/#some-notes","text":"This is a very good just-in-time moment to emphasize a few points points.","title":"Some notes"},{"location":"3-pytest-introduction/#anatomy-of-a-test","text":"Firstly, let's revise now what the anatomy of a test is like. You will always have a setup, a result from the execution of the function, and an assertion about the result. from module import function def test_function (): # `test_` in the name is very important! \"\"\"Docstring about the test.\"\"\" setup_value = ... # set up the test result = function ( setup_value ) # execution of the function assert result == correct_val # assertion statement The function should do something that is \"testable\", and ideally, it should run fast (like under a few hundred milliseconds). After all, if you start accumulating a bunch of functions and need to test them, then you'll end up waiting a long time for all of your tests to run.","title":"Anatomy of a Test"},{"location":"3-pytest-introduction/#testing-loop","text":"The other thing to introduce just-in-time here is the so-called \"testing loop\": Write a test for a function. Write the function. Execute pytest . Go back to step 1. There's nothing complex behind the ideas of testing, 80% of your cases will boil down to doing this loop.","title":"Testing Loop"},{"location":"3-pytest-introduction/#what-kinds-of-tests","text":"There are a few kinds of tests that you can write, and I'll list here the \"bare minimum\".","title":"What kinds of tests"},{"location":"3-pytest-introduction/#execution-tests","text":"If you don't do anything else, then simply executing the test and making sure it runs without erroring is better than nothing. (Basically, just eliminate the assertions.) I don't recommend doing this for everything, but if you're genuinely at a loss, then call the function inside the test and just make sure it doesn't error out.","title":"Execution tests"},{"location":"3-pytest-introduction/#example-based-tests","text":"I did this in test_increment , where I provided one example input in the test, and tested that the expected result was some exact value. This is already one level up from a simple execution test.","title":"Example-based tests"},{"location":"3-pytest-introduction/#parametrized-tests","text":"You can read more about parametrizing a test on the pytest docs . Here, we parametrize the test function, so that pytest can provide to it a range of examples that we have pre-defined.","title":"Parametrized tests"},{"location":"3-pytest-introduction/#property-based-tests","text":"If you read test_increment_general , that is an example of a property-based test. There, we test a property of the output that is invariant to the input given, i.e. that the output should always be one more than the input, regardless of what input is given. In the later chapters, you will see how to do this with Hypothesis.","title":"Property-based tests"},{"location":"3-pytest-introduction/#exercise-3-testing-a-min-max-scaler","text":"In functions.py , we have a function called min_max_scaler(x) for your data. It takes in a numpy array and scales all of the values to be between 0 and 1 inclusive. The min value should be 0, and the max value should be 1. Try writing a test for the min-max scaler. It should check the following: Given a particular array-like input (e.g. numpy array, list, tuples), it should be equal to some other array. Use the np.allclose(arr1, arr2) function to test closeness of two floating point values. The minimum value should be 0, and the maximum value of the output should be 1. Note: This function is also implemented in the scikit-learn library as part of their preprocessing module. However, in case an engineering decision that you make is that you don't want to import an entire library just to use one function, it is considered good practice to rewrite it on your own, provided you also test it sufficiently. Once you're done, execute the test and check that the min_max_scaler adheres to the behaviour laid out in its docstring.","title":"Exercise 3: Testing a Min-Max Scaler"},{"location":"3-pytest-introduction/#exercise-4-testing-functions-on-textual-data","text":"Imagine we have textual data, and we want to clean it up. There are two functions we may want to write to standardize the data: bag_of_words(text) , which takes in the text and tokenizes the text into its set of constituent words. strip_punctuation(text) , which strips punctuation from the text. Now, I'd like you to invert the flow we've been following, and start by designing the tests first, before implementing the two functions in src/student_functions.py ; you may wish to write additional helper functions to manage the business logic. There's leeway in this exercise; feel free to get creative! (And if you want a reference starting point, feel free to peek inside src/functions.py !) The reason I'm asking you to design the tests first is because that will clarify how you intend to use the function, which will bring much more clarity to how you implement the function. This is also known as \"Test-Driven Development\". Once you're done, execute the tests and make sure they all pass.","title":"Exercise 4: Testing functions on textual data."},{"location":"3-pytest-introduction/#conclusions","text":"This level of testing is sufficient to get you through 80% of the day-to-day. I have used this level of testing at work to raise the level of confidence I have in the functions I write. It facilitates code sharing as well, because my colleagues can now have the confidence that the code I write is reliable and works as expected. My engineering colleagues will have confidence in taking over what I have developed, because they know they have an easy starting point for studying the code (in the test suite). There are advanced patterns for testing that I have not gone through here, such as parametrizing the tests, checking that errors are raised, and more. For these, the pytest docs are a wonderful resource, and I would encourage you to check them out. Meanwhile, we are going to go to the next chapter, which is on how writing tests for our data.","title":"Conclusions"}]}